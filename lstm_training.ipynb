{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36de929c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- 1. INSTALL LIBRARIES ---\n",
    "print(\"STEP 1: Installing required libraries...\")\n",
    "!pip install -q tensorflow keras scikit-learn pandas joblib\n",
    "print(\"Libraries installed successfully.\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 2. IMPORT LIBRARIES & CONFIGURE ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import joblib\n",
    "import os\n",
    "import xml.etree.ElementTree as ET # Library to read XML files\n",
    "import csv # Library to write CSV files\n",
    "\n",
    "# --- Configuration ---\n",
    "# The file you will upload from Kaggle\n",
    "INPUT_XML_FILE = '559-ws-training.xml'\n",
    "# The file we will create for our model\n",
    "OUTPUT_CSV_FILE = 'glucose_data.csv'\n",
    "\n",
    "MODEL_SAVE_PATH = 'glucose_predictor.h5'\n",
    "SCALER_SAVE_PATH = 'scaler.gz'\n",
    "LOOK_BACK = 12\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# --- 3. CONVERT XML TO CSV (This runs AFTER you upload) ---\n",
    "print(f\"STEP 2: Ready for data. Please upload '{INPUT_XML_FILE}' now.\")\n",
    "\n",
    "if os.path.exists(INPUT_XML_FILE):\n",
    "    print(f\"STEP 3: XML file found! Converting '{INPUT_XML_FILE}' to '{OUTPUT_CSV_FILE}'...\")\n",
    "\n",
    "    # Parse the XML file\n",
    "    tree = ET.parse(INPUT_XML_FILE)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Open a new CSV file to write to\n",
    "    with open(OUTPUT_CSV_FILE, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        # Write the header row\n",
    "        writer.writerow(['timestamp', 'glucose_value'])\n",
    "        # Find all 'event' tags and write their data to the CSV\n",
    "        for event in root.findall('./glucose_level/event'):\n",
    "            ts = event.get('ts')\n",
    "            value = event.get('value')\n",
    "            writer.writerow([ts, value])\n",
    "\n",
    "    print(\"Conversion complete!\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # --- 4. PREPARE THE DATA from our NEW CSV file ---\n",
    "    def create_sequences(dataset, look_back):\n",
    "        dataX, dataY = [], []\n",
    "        for i in range(len(dataset) - look_back - 1):\n",
    "            a = dataset[i:(i + look_back), 0]\n",
    "            dataX.append(a)\n",
    "            dataY.append(dataset[i + look_back, 0])\n",
    "        return np.array(dataX), np.array(dataY)\n",
    "\n",
    "    print(\"STEP 4: Loading and preparing data from the new CSV file...\")\n",
    "    df = pd.read_csv(OUTPUT_CSV_FILE, usecols=['glucose_value']).dropna().reset_index(drop=True)\n",
    "    dataset = df.values.astype('float32')\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    dataset_scaled = scaler.fit_transform(dataset)\n",
    "    trainX, trainY = create_sequences(dataset_scaled, LOOK_BACK)\n",
    "    trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "    print(\"Data preparation complete.\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # --- 5. BUILD AND TRAIN THE MODEL ---\n",
    "    print(\"STEP 5: Building and training the LSTM model...\")\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(16, input_shape=(LOOK_BACK, 1)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(trainX, trainY, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)\n",
    "    print(\"Model training complete.\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # --- 6. SAVE THE RESULTS ---\n",
    "    print(\"STEP 6: Saving the trained model and scaler...\")\n",
    "    model.save(MODEL_SAVE_PATH)\n",
    "    joblib.dump(scaler, SCALER_SAVE_PATH)\n",
    "    print(f\"Artifacts saved: '{MODEL_SAVE_PATH}' and '{SCALER_SAVE_PATH}'\")\n",
    "    print(\"\\n--- ALL DONE! You can now download your files from the file pane. ---\")\n",
    "else:\n",
    "    print(f\"\\nERROR: Could not find the file. Please upload '{INPUT_XML_FILE}' and then run this cell again.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
